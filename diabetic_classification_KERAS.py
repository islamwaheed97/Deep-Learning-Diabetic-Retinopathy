# -*- coding: utf-8 -*-
"""Diabetic_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t93Do0MkmQJxcqhy9EYC4ZhfQkiQO70F
"""

from google.colab import drive
drive.mount('/content/drive')

import os
base_dir = '/content/drive/My Drive/dataaaaaaa/Engz'
train_dir = os.path.join(base_dir, 'Engz')
#train_dir2 = os.path.join(base_dir, 'Validate')
#validation_dir = os.path.join(base_dir,'lvl3_validate')

validation_dir = os.path.join(base_dir, 'Validate')

train_cats_dir = os.path.join(train_dir,'level_zero2')
train_dogs_dir = os.path.join(train_dir,'Train_Diabetic2')

validation_cats_dir = os.path.join(validation_dir,'Validate_lvl0')
validation_dogs_dir = os.path.join(validation_dir,'Validate_Diabetic')

train_cat_fnames = os.listdir(train_cats_dir)
print(train_cat_fnames[:10])

train_dog_fnames = os.listdir(train_dogs_dir)
train_dog_fnames.sort()
print(train_dog_fnames[:10])

# '''print('total training lvl_1 images:', len(os.listdir(train_cats_dir)))
# print('total training lvl_2 images:', len(os.listdir(train_dogs_dir)))
# print('total validation lvl_1 images:', len(os.listdir(validation_cats_dir)))
# print('total validation lvl_2 images:', len(os.listdir(validation_dogs_dir)))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

nrows = 4
ncols = 4

pic_index = 0

fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)

pic_index += 8
next_cat_pix = [os.path.join(train_cats_dir, fname) 
                for fname in train_cat_fnames[pic_index-8:pic_index]]
next_dog_pix = [os.path.join(train_dogs_dir, fname) 
                for fname in train_dog_fnames[pic_index-8:pic_index]]

for i, img_path in enumerate(next_cat_pix+next_dog_pix):
  
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') 

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

#from PIL import Image 
  #print(img_path)
# open method used to open different extension image file 
#im = Image.open(r"C:\Users\System-Pc\Desktop\ybear.jpg")  
  
# This method will show image in any image viewer  
#im.show()

from tensorflow.keras import layers
from tensorflow.keras import Model

img_input = layers.Input(shape=(150, 150, 3))

x = layers.Conv2D(32, 10, activation='relu')(img_input)

x = layers.MaxPooling2D(2)(x)

x = layers.Conv2D(32, 10, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

x = layers.Conv2D(32, 10, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)

!cat /proc/gpuinfo

x = layers.Flatten()(x)

x = layers.Dense(512, activation='relu')(x)

output = layers.Dense(1, activation='sigmoid')(x)

model = Model(img_input, output)

model.summary()

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255  ~~~~sameee
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

validation_generator = val_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

#len(train_datagen)[0].shape
len(train_generator)
#train_datagen[0].shape

# import datetime
# import tensorflow as tf
# log_dir="logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

history = model.fit_generator(
      train_generator,
      steps_per_epoch=5,  # 2000 images = batch_size * steps
      epochs=10,
      validation_data=validation_generator,
      validation_steps=10, # 1000 images = batch_size * steps
      verbose=2, 
                )

# !tensorboard dev upload --logdir ./logs \
#   --name "Simple experiment with MNIST" \
#   --description "Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb"

import numpy as np
import random
from tensorflow.keras.preprocessing.image import img_to_array, load_img


successive_outputs = [layer.output for layer in model.layers[1:]]
visualization_model = Model(img_input, successive_outputs)


cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]
dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]
img_path = random.choice(cat_img_files + dog_img_files)

img = load_img(img_path, target_size=(150, 150))  
x = img_to_array(img)  
x = x.reshape((1,) + x.shape)  

# Rescale by 1/255
x /= 255

successive_feature_maps = visualization_model.predict(x)

layer_names = [layer.name for layer in model.layers]

for layer_name, feature_map in zip(layer_names, successive_feature_maps):
  if len(feature_map.shape) == 4:
    n_features = feature_map.shape[-1]  
    size = feature_map.shape[1]
    display_grid = np.zeros((size, size * n_features))
    for i in range(n_features):
      x = feature_map[0, :, :, i]
      x -= x.mean()
      x /= x.std()
      x *= 64
      x += 128
      x = np.clip(x, 0, 255).astype('uint8')
      display_grid[:, i * size : (i + 1) * size] = x

    scale = 20. / n_features
    plt.figure(figsize=(scale * n_features, scale))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

#len(train_datagen)

acc = history.history['acc']
val_acc = history.history['val_acc']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc)
plt.plot(epochs, val_acc)
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epochs, loss)
plt.plot(epochs, val_loss)
plt.title('Training and validation loss')

#import os, signal
#os.kill(os.getpid(), signal.SIGKILL)